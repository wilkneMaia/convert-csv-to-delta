![Comparativo CSV vs Delta Lake](comparativo_delta_linkedin.png)


# Do CSV ao Delta Lake: Armazenando e Consultando Dados Frios com Python e SQL

## ğŸš€ VisÃ£o Geral

Este projeto demonstra como converter grandes arquivos CSV de dados frios em tabelas Delta Lake (Parquet Snappy), otimizando o armazenamento e acelerando consultas SQL. Utilizando Python, PySpark e Delta Lake, vocÃª reduz custos, ganha performance e prepara seus dados para anÃ¡lise moderna.

---

## ğŸ“¦ Principais BenefÃ­cios

- **ReduÃ§Ã£o de espaÃ§o:** De 1.8 GB (CSV) para 216 MB (Delta Lake) - compressÃ£o de 8x+
- **Consultas SQL ultrarrÃ¡pidas:** 14x mais rÃ¡pido que CSV puro
- **Pronto para BI:** IntegraÃ§Ã£o nativa com Spark, Databricks, Athena, Power BI, etc.
- **GovernanÃ§a e escalabilidade:** TransaÃ§Ãµes ACID, versionamento, time travel e schema evolution

---

## âš¡ Pipeline

1. **Leitura do CSV:** InferÃªncia automÃ¡tica de schema
2. **SanitizaÃ§Ã£o de colunas:** PadronizaÃ§Ã£o de nomes para compatibilidade SQL
3. **ConversÃ£o para Delta Lake:** CompressÃ£o Snappy e escrita otimizada
4. **Consulta SQL:** Filtros e agregaÃ§Ãµes rÃ¡pidas sobre grandes volumes de dados frios

---

## ğŸ“Š Resultados Reais

| MÃ©trica         | CSV        | Delta Lake | Ganho      |
|-----------------|------------|------------|------------|
| Tamanho         | 1807 MB    | 216 MB     | 8.3x menor |
| Tempo de Query  | 12.4 s     | 0.86 s     | 14x mais rÃ¡pido |

> **GrÃ¡fico acima:** ReduÃ§Ã£o de espaÃ§o e ganho de performance ao migrar dados frios de CSV para Delta Lake.

---

## ğŸ” Exemplo de Uso

### ConversÃ£o para Delta Lake

---

## ğŸ› ï¸ Requisitos

- Python ^3.11
- PySpark ^3.5.5
- delta-spark ^3.3.1
- Java 8/11

---

## ğŸ“‚ Estrutura do Projeto

.
â”œâ”€â”€ **pycache**
â”‚   â””â”€â”€ pyspark.cpython-312.pyc
â”œâ”€â”€ app.py
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ csv
â”‚   â”‚   â”œâ”€â”€ central_west.csv
â”‚   â”‚   â”œâ”€â”€ columns_description.csv
â”‚   â”‚   â”œâ”€â”€ north.csv
â”‚   â”‚   â”œâ”€â”€ northeast.csv
â”‚   â”‚   â”œâ”€â”€ south.csv
â”‚   â”‚   â”œâ”€â”€ southeast.csv
â”‚   â”‚   â””â”€â”€ stations.csv
â”‚   â””â”€â”€ delta
â”‚       â”œâ”€â”€ _delta_log
â”‚       â”‚   â”œâ”€â”€ 00000000000000000000.crc
â”‚       â”‚   â”œâ”€â”€ 00000000000000000000.json
â”‚       â”‚   â””â”€â”€ _commits
â”‚       â””â”€â”€ part-00000-430a3d82-1a95-4ce5-9ebd-81dafdfa6396-c000.snappy.parquet
â”œâ”€â”€ query_delta_table.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ utils
    â”œâ”€â”€ **init**.py
    â”œâ”€â”€ **pycache**
    â”‚   â”œâ”€â”€ **init**.cpython-312.pyc
    â”‚   â”œâ”€â”€ config.cpython-312.pyc
    â”‚   â”œâ”€â”€ convert_csv_to_parquet.cpython-312.pyc
    â”‚   â”œâ”€â”€ convert_parquet_to_delta.cpython-312.pyc
    â”‚   â””â”€â”€ convert_parquet_to_table.cpython-312.pyc
    â”œâ”€â”€ config.py
    â”œâ”€â”€ convert_parquet_to_delta.py
    â””â”€â”€ data_loader.ipynb

9 directories, 23 files

---

## ğŸ¤ Contribua e Compartilhe

- Teste o pipeline com seus prÃ³prios dados frios.
- Compartilhe sua experiÃªncia ou dÃºvidas na seÃ§Ã£o de Issues ou nos comentÃ¡rios do LinkedIn.
- Pull requests sÃ£o bem-vindos!

---

## ğŸ“ ReferÃªncias

- [Delta Lake Documentation](https://docs.delta.io/latest/index.html)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [delta-io/delta-examples](https://github.com/delta-io/delta-examples)
- [Kaggle - dataset](https://www.kaggle.com/datasets/PROPPG-PPG/hourly-weather-surface-brazil-southeast-region)

---

**Vamos juntos modernizar o tratamento de dados frios!** ğŸš€
